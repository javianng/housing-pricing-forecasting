{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the MRT Dataset\n",
    "\n",
    "In this notebook, we will be using the `requests` and `BeautifulSoup` python libraries to scrape MRT stations, their respective coordinates and opening dates from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a request to `https://en.wikipedia.org/wiki/List_of_Singapore_MRT_stations` to find all MRT stations and their respective Wikipedia links; we can store these information with MRT station name being the key and the respective wikipedia page as the value. \n",
    "\n",
    "Note that since we will be adding on the MRT station's coordinates and opening dates as well, we can let the values in the dictionary be a list that will store the Wikipedia link, coordinates and opening date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "# make request to wikepdia page\n",
    "res = requests.get('https://en.wikipedia.org/wiki/List_of_Singapore_MRT_stations')\n",
    "# parse the page\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "td_elements = soup.find_all('td')\n",
    "\n",
    "mrt_stations = [td.find('a', title=lambda title: title and \"MRT station\" in title) for td in td_elements if td.find('a', title=lambda title: title and \"MRT station\" in title)]\n",
    "\n",
    "station_dict = {}\n",
    "for station in mrt_stations:\n",
    "    if station:  # Check to make sure the station is not None\n",
    "        station_name = station.text.strip()  # .strip() removes leading/trailing whitespace\n",
    "        if station_name in station_dict:\n",
    "            continue  # Skip this station if it's already been processed\n",
    "        station_link = \"https://en.wikipedia.org\" + station['href']\n",
    "        station_dict[station_name] = [station_link]\n",
    "\n",
    "print(len(station_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each unique MRT station, we access their Wikipedia link and obtain the coordinates and opening date.\n",
    "\n",
    "Note that Wikepedia gives coordinates in the following format `1°20′00″N` so we have to create a function to convert the coordinates into decimal coordiantes too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to convert coordinates into decimal\n",
    "def convert_coordinates(coordinate):\n",
    "    coordinate = coordinate.replace('°', ' ').replace('′', ' ').replace('″', ' ')\n",
    "    parts = coordinate.split()\n",
    "    degrees = float(parts[0])\n",
    "    minutes = float(parts[1])\n",
    "    seconds = float(parts[2])\n",
    "    decimal = degrees + minutes / 60 + seconds / 3600\n",
    "    return decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurong East: 1.3333333333333333, 103.74222222222222 - 5 November 1988\n",
      "Bukit Batok: 1.3491666666666666, 103.74972222222222 - 10 March 1990\n",
      "Bukit Gombak: 1.3586111111111112, 103.75166666666667 - 10 March 1990\n",
      "Brickland: 1.3686111111111112, 103.74944444444445 - Not opened yet\n",
      "Yew Tee: 1.396986111111111, 103.74723888888889 - 10 February 1996\n",
      "Sungei Kadut: 1.4133333333333333, 103.74888888888889 - Not opened yet\n",
      "Kranji: 1.4250472222222224, 103.76185277777778 - 10 February 1996\n",
      "Marsiling: 1.4326361111111112, 103.77428333333333 - 10 February 1996\n",
      "Woodlands: 1.4370944444444445, 103.78648333333334 - 10 February 1996\n",
      "Admiralty: 1.440688888888889, 103.80093333333333 - 10 February 1996\n",
      "Sembawang: 1.449025, 103.82015277777778 - 10 February 1996\n",
      "Canberra: 1.4430555555555555, 103.82972222222222 - 2 November 2019\n",
      "Yishun: 1.4294638888888889, 103.83523888888888 - 20 December 1988\n",
      "Khatib: 1.4171666666666667, 103.8329 - 20 December 1988\n",
      "Yio Chu Kang: 1.3819055555555555, 103.84481666666666 - 7 November 1987\n",
      "Ang Mo Kio: 1.3700166666666667, 103.84944999999999 - 7 November 1987\n",
      "Bishan: 1.3511111111111112, 103.84833333333333 - 7 November 1987\n",
      "Braddell: 1.3403388888888887, 103.84672499999999 - 7 November 1987\n",
      "Toa Payoh: 1.3327777777777778, 103.8475 - 7 November 1987\n",
      "Novena: 1.3203944444444444, 103.84368888888888 - 12 December 1987\n"
     ]
    }
   ],
   "source": [
    "# iterate through station_dict\n",
    "for station in station_dict:\n",
    "    # make request to station link\n",
    "    res = requests.get(station_dict[station][0])\n",
    "    # parse the page\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    # get the latitude and longitude\n",
    "    latitude = convert_coordinates(soup.find('span', class_='latitude').text)\n",
    "    longitude = convert_coordinates(soup.find('span', class_='longitude').text)\n",
    "\n",
    "    # get the opening date\n",
    "    opened_row = soup.find('th', string='Opened')\n",
    "    if opened_row:\n",
    "        # Find the next sibling of the 'opened_row' which is the 'td' containing the date\n",
    "        opened_date_cell = opened_row.find_next_sibling('td')\n",
    "        # Extract the text, split by '<br>' if multiple dates exist, and strip to clean it up\n",
    "        opened_date = opened_date_cell.text.split('<br>')[0].strip()\n",
    "        # Replace HTML entities with their corresponding characters, e.g., '&nbsp;' with ' '\n",
    "        opened_date = opened_date.replace(u'\\xa0', u' ')\n",
    "        # get the cleaned date\n",
    "        opened_date = opened_date.split(';')[0]\n",
    "    else:\n",
    "        opened_date = 'Not opened yet'\n",
    "\n",
    "    # add the latitude, longitude and opening date to the station_dict\n",
    "    station_dict[station].append(latitude)\n",
    "    station_dict[station].append(longitude)\n",
    "    station_dict[station].append(opened_date)\n",
    "\n",
    "# print out first 20 stations with their coordinates and opening dates\n",
    "for station, data in list(station_dict.items())[:20]:\n",
    "    print(f'{station}: {data[1]}, {data[2]} - {data[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the station_dict into csv format with columns: `mrt_station_name` `latitude` `longtitude` `opening_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert station_dict into csv\n",
    "with open('../data/modified/mrt_stations.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['mrt_station_name', 'latitude', 'longitude', 'opening_date'])\n",
    "    for station, data in station_dict.items():\n",
    "        writer.writerow([station + ' MRT Station', data[1], data[2], data[3]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
